I'll work through all of these systematically. Let me start reading.I've now read through all of these sources (with the exception of the Ocula piece, which was behind a paywall — though I got substantial excerpts from search results). Here's my honest take.

---

## 1. The State of the Discourse

The conversation around AI slop has crystallized into roughly three camps, and none of them is entirely wrong.

**The dominant position — and the one with the most cultural energy right now — is disgust.** Writers like Ted Gioia, the *Perilous Tech* author Nathan Hamiel, and Sarah Stumböck are making essentially the same argument from different angles: AI-generated content is flooding digital spaces with material that is formally competent but spiritually empty. It drowns out human creators, incentivizes grift over craft, and degrades our collective attention. Gioia frames this as the inversion of the modernist impulse — where Ezra Pound said "Make It New," the Age of Slop says "Make It Whack." Hamiel goes further, arguing that an entire generation may grow up unable to distinguish between resolution and quality, confusing visual fidelity with artistic merit. The Nick Cave quote that Stumböck surfaces — about algorithms having no inner being, having endured nothing — is probably the single most cited passage in the entire anti-slop discourse, and for good reason. It's sharp and it *feels* true.

**The strongest version of this argument** isn't about aesthetics at all — it's about economics and infrastructure. The Wikipedia article documents how AI slop is disproportionately produced by people in developing countries gaming advertising platforms for revenue, using tools in languages those tools weren't even optimized for. Stumböck cites the case of Michael Smith, who used AI to generate hundreds of thousands of fake tracks and siphoned millions in streaming royalties. This isn't an aesthetic debate — it's a description of a system in which the infrastructure of culture has been hijacked for extraction. The strongest anti-slop argument is fundamentally an argument about platform capitalism, not about taste.

**The countervailing position — represented best by the *Scientific American* piece and the *MIT Technology Review* article — is historical patience.** Béchard in *Scientific American* traces a pattern from Gutenberg through Grub Street through nickelodeons: every new production technology generates a flood of garbage, and within that flood, new forms of genuine art eventually emerge. The MIT piece profiles artists like Jacob Adler, Kira Xonorika, and Beth Frey who are using AI tools with real intentionality — and notably, Frey found the tools *more* interesting when they were worse, when the glitches were still there. The argument here isn't that slop is good; it's that condemning an entire medium because of its worst outputs is a mistake history keeps warning us about.

**The third position — and the most intellectually interesting — is represented by the *Augmented Educator* piece and the Near Future Laboratory essay.** Wagner draws a detailed parallel between AI slop and kitsch, tracing how "kitsch" went from pure pejorative to the raw material of Pop Art, camp sensibility, and eventually Jeff Koons. Julian Bleecker, revisiting Hal Foster's *The Anti-Aesthetic*, argues that what's being automated isn't just technique but *judgment* — the slow negotiation between maker, material, and meaning — and that when a system fills that space, it collapses the moment where thinking actually happens. This is the sharpest critique I encountered in all this reading, because it identifies the actual mechanism of loss rather than just lamenting the outcome.

---

## 2. Historical Patterns

Yes, this has happened before. Repeatedly. But the parallels are imperfect in ways that matter.

The *Scientific American* piece makes the strongest case for historical rhyme: Gutenberg's press led to chapbooks and broadside ballads, Grub Street churned out pamphlets and hack journalism, nickelodeons ran nonstop shows — and in each case, the garbage became the substrate from which real culture grew. This is accurate. Samuel Johnson came out of Grub Street. Scorsese and Coppola came out of B-movies. The internet produced both SEO spam and entirely new literary and visual forms.

But there's a structural difference this time that most of these pieces only gesture at. In every previous media revolution, the cost of *production* dropped, but there was still meaningful human labor in the loop. A penny-press author still had to write. A nickelodeon filmmaker still had to shoot. What's different about generative AI is that the marginal cost of production has collapsed to near zero *and* the human involvement in each unit of output can be near zero. Béchard acknowledges this — the cost for makers has collapsed while the cognitive cost for consumers (of sorting, doubting, paying attention) has risen. This asymmetry is genuinely new.

The closer historical parallel isn't actually the printing press — it's photography. When photography arrived, the dominant fear was that it would kill painting by rendering realism trivially achievable. What actually happened was that photography *freed* painting from the obligation to be representational, which gave us Impressionism, Cubism, and eventually abstraction. The question is whether AI will similarly free human creators from certain kinds of labor and push them toward what only humans can do. I think the answer is probably yes, but the transition will be far more brutal than the photography-painting transition because the economic displacement is happening much faster and across far more domains simultaneously.

---

## 3. The Line Between "AI Slop" and "AI Art"

There is a meaningful distinction, and it maps fairly cleanly onto the concept Simon Willison originally articulated: slop is AI-generated content that is **mindlessly generated and thrust upon someone who didn't ask for it.** The key variables are *intention* and *audience consent.*

The MIT piece makes this concrete. Beth Frey spent months iterating with early AI models, drawn specifically to their uncanniness and errors — she found them less interesting as they became more polished. Kira Xonorika treats unpredictability as a creative collaborator, and her work is now in the Denver Art Museum's permanent collection. These are people making choices at every stage — what to prompt, what to keep, what to discard, how to contextualize the result. That's art-making. A Kenyan content farmer asking ChatGPT to generate engagement-bait Jesus images for Facebook is not making choices in that sense. The tool is the same; the practice is entirely different.

Ted Chiang's formulation, cited in the *Perilous Tech* piece, is the best I've seen: art results from making a lot of choices, and a ten-thousand-word story requires something on the order of ten thousand choices, while a hundred-word prompt requires about a hundred. This is elegant but too neat. A photographer also makes relatively few mechanical choices (framing, timing, exposure) compared to a painter, and we've long since accepted photography as art. The number of choices matters less than their *quality* and the depth of intention behind them.

Where I'd draw the line: AI art is what happens when a human uses generative tools as part of a practice that involves genuine artistic judgment — selection, curation, iteration, contextualization, and a willingness to fail and try again. AI slop is what happens when those tools are used to generate volume with no judgment applied, or when the "judgment" is purely algorithmic (what will get clicks). The Ocula piece makes an interesting distinction between artists who engage critically with AI — like Maya Man training models on *Dance Moms* screenshots to explore mimesis and performance — and what Walleston calls "schlock-slop," which is just formalist abstraction without even a nod to art history.

---

## 4. What's Missing from the Conversation

Several things.

**First, almost nobody is talking about the class dynamics honestly.** The Wikipedia article mentions that slop production is often driven by people in developing countries gaming platforms for advertising revenue from wealthier markets. This is glossed over in most cultural criticism as though it's an incidental detail. It's not. It's the entire engine. AI slop isn't primarily an aesthetic problem — it's what happens when global labor arbitrage meets zero-marginal-cost content production meets ad-funded platform economics. Fixing slop without fixing the incentive structure is like mopping the floor while the tap is running.

**Second, the discourse is almost entirely focused on visual art and text, with music as an afterthought.** But AI-generated music may be the domain where the most damage is being done most quietly. Deezer estimated that nearly a fifth of all new music uploads to its platform are entirely AI-generated. That's not a cultural debate — that's a fait accompli. The streaming economy was already badly broken for artists; AI slop is breaking it further, and almost none of the high-profile cultural criticism addresses this with the urgency it deserves.

**Third, nobody is seriously reckoning with the environmental cost.** Every one of these AI-generated images and videos requires compute. The discourse treats slop as an aesthetic and economic problem, but it's also a thermodynamic one. We are burning actual energy to produce content that nobody values.

**Fourth — and this is the big one — the anti-slop discourse has a serious blind spot around its own elitism.** Many of these pieces implicitly assume that "real" art requires formal training, deep suffering, or at minimum a kind of intentionality that can only come from years of practice. That's true for a lot of art. But it also describes the worldview of a professional creative class that has historically gatekept who gets to call themselves an artist. Daubrez, in the MIT piece, makes a point worth taking seriously: people who had long since given up on creative expression are now creating and sharing work. The anti-slop critics are right that most of this work is bad. But the democratization of creative tools has *always* produced mostly bad work. That was true of garage bands, self-published novels, and YouTube. Dismissing all of it as slop because it lacks the markers of professional craft risks confusing quality with credentialism.

**Fifth, almost no one is asking the uncomfortable question about consumption.** If millions of people are happily consuming AI slop on Facebook — sharing Shrimp Jesus, engaging with fake veteran images — what does that tell us about what people actually want from visual culture? The anti-slop argument often treats audiences as victims of algorithmic manipulation, which is partly true. But it's also partly a refusal to confront the possibility that much of the public never wanted what professional creatives were offering. The history of kitsch, as Wagner's piece documents, is largely the history of elite taste-makers being horrified that ordinary people prefer sentimental, accessible, unchallenging images. That's not a new problem. AI just made it louder.

---

## 5. The Manifestos and This Moment

The parallels are real but limited, and it matters which manifesto you're comparing to.

**The Futurist Manifesto** is the more tempting comparison, and the more dangerous one. Marinetti's manifesto is a document drunk on technology — on speed, machines, violence, the destruction of the old. It explicitly calls for the demolition of museums, libraries, and academies. At first glance, Silicon Valley's orientation toward creative work looks similar: move fast, break things, automate the old gatekeepers out of existence. Gioia makes this comparison implicitly by contrasting the era of artistic manifestos with the era of web platforms.

But the comparison fails in a crucial way. The Futurists were *artists* who wanted to use technology to make art that felt like the modern world. They had an aesthetic vision — a theory of beauty rooted in speed, dynamism, and industrial energy. The tech companies producing AI tools have no aesthetic vision at all. They have a business model. Marinetti wanted to destroy museums because he thought they were mausoleums for dead culture. AI companies don't want to destroy anything in particular — they want to reduce the cost of content production to zero because that's where the margin is. The Futurist Manifesto is a love letter to the machine as a source of beauty. The AI slop economy treats the machine as a source of revenue. These are fundamentally different orientations, and conflating them flatters Silicon Valley with an intellectual seriousness it hasn't earned.

There's also the dark side that tends to get elided: Marinetti's glorification of war and his eventual embrace of fascism weren't incidental to Futurism. They were baked into a worldview that celebrated destruction and speed as inherently noble. The AI moment has its own version of this — the "move fast and break things" ethos applied to human livelihoods and cultural institutions — and it's worth remembering where Futurism's worship of the machine actually led.

**The Surrealist Manifesto** is a more productive comparison, though it's rarely made. Breton's document is fundamentally about the liberation of the unconscious — about accessing the parts of human experience that rational, utilitarian culture suppresses. Surrealism was obsessed with dreams, chance, automatic writing, and the irrational. There's a genuine parallel here with certain uses of AI: the early, glitchy outputs of image generators — the extra fingers, the melting faces — had an uncanny, dreamlike quality that some artists found genuinely compelling. Beth Frey's attraction to early AI's errors, the sense that the tools were producing something alien and surprising, is essentially a Surrealist sensibility applied to a new medium.

But the parallel breaks down because Surrealism was a *practice of liberation* — it was about freeing the human mind from the tyranny of reason. AI generation isn't liberating anyone's unconscious. It's interpolating between patterns in training data. The randomness of AI outputs isn't the randomness of dreams; it's the randomness of statistical noise. Breton would have been fascinated by AI, I think, but he would have recognized immediately that a machine that produces surprising images by recombining its training data is doing something fundamentally different from a human who accesses their own unconscious through automatic writing. The Surrealists were interested in what lies *beneath* rational thought. AI doesn't have a beneath.

The most useful historical framework is actually the one Bleecker invokes — not a manifesto but a critical text: Hal Foster's *The Anti-Aesthetic*. Foster's argument was that postmodern art needed to resist the spectacle of smooth surfaces and reveal its own construction. That feels far more relevant to the current moment than either Futurism or Surrealism. The problem with AI slop isn't that it's ugly or shocking — it's that it's *smooth.* Every output looks finished. And that smoothness conceals the absence of intention, choice, and risk. As Bleecker puts it, what's being automated is not just technique but judgment, and when a system fills the space where judgment should be, it collapses the moment where thinking actually happens.

If there's a manifesto to be written for this moment, it probably shouldn't be *for* or *against* AI. It should be for the preservation of friction — for the insistence that the space between intention and output is where meaning lives, and that any tool or system that eliminates that space, no matter how technically impressive, is working against art rather than for it.